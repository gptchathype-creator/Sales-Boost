# Голосовой контур в звонке: ASR → LLM → TTS (подробно)

Два блока: (1) как звонить на один номер или на список тестовых; (2) пошаговая логика обработки речи и ответа — где ASR, что делаем с текстом, где LLM, кто делает TTS и почему.

---

## 1. Тестовые номера: один или список

В `.env` задаётся:

- **`VOX_TEST_TO`** — один номер по умолчанию (если в запросе не указан `to`).
- **`VOX_TEST_NUMBERS`** — несколько номеров через запятую, без пробелов, например:  
  `VOX_TEST_NUMBERS=+79778117475,+79001234567,+79001234568`

**Как звонить:**

| Задача | Метод | Тело запроса |
|--------|--------|---------------|
| Позвонить на **конкретный** номер | `POST /call` | `{ "to": "+79XXXXXXXXX" }` |
| Позвонить на номер по умолчанию | `POST /call` | `{}` или `{ "to": null }` — возьмётся `VOX_TEST_TO` |
| Позвонить на **все тестовые** номера из конфига | `POST /batch` | `{ "use_test_numbers": true }` — будут использованы номера из `VOX_TEST_NUMBERS` |
| Позвонить на свой список номеров | `POST /batch` | `{ "numbers": ["+79a", "+79b", "+79c"] }` |

Список тестовых номеров из env можно посмотреть: **`GET /test-numbers`** — в ответе будут `test_numbers` и `default_to`.

---

## 2. Что такое ASR и где он стоит

**ASR (Automatic Speech Recognition)** — распознавание речи в текст (Speech-to-Text). В звонке голос менеджера нужно превращать в текст, чтобы:

- передать реплику в нашу логику виртуального клиента (LLM);
- вести диалог и оценку так же, как в чате.

Рекомендация: **ASR делать на стороне Voximplant** (в сценарии), профиль для русского — **Yandex** или **T‑bank**. Так минимальная задержка и не нужна пересылка аудио на наш сервер.

---

## 3. Пошаговая схема: от речи менеджера до голоса «клиента»

Ниже — полная цепочка: кто что делает и что с текстом происходит.

### Шаг 1: Речь менеджера → текст (ASR в Voximplant)

- **Где:** сценарий Voximplant (VoxEngine).
- **Как:** в сценарии создаётся ASR (`VoxEngine.createASR`), аудио из звонка передаётся в ASR (`call.sendMediaTo(asr)`), выбран профиль с русским (Yandex или T‑bank). При появлении распознанного текста (событие `ASREvents.Result`, при необходимости и `InterimResult`) сценарий **отправляет этот текст на наш бэкенд** по webhook (например `POST /voice/dialog` с телом `{ session_id, text, is_final }`).
- **Результат:** у нас на бэкенде есть **текст реплики менеджера** (и флаг, промежуточный он или финальный).

Итог: **текст из звонка обрабатывается только у нас** — мы его получаем уже после ASR. Сам ASR выполняется в Voximplant для скорости и качества русского.

### Шаг 2: Обработка текста у нас — состояние диалога и LLM

- **Где:** наш бэкенд (тот же сервер, где логика бота, или отдельный сервис, который использует те же модули).
- **Что делаем с текстом:**
  1. По `session_id` достаём или создаём состояние диалога (фазы, темы, история реплик — та же модель, что в чате).
  2. Добавляем реплику менеджера в историю как текст (как в боте).
  3. При необходимости прогоняем текст через **BehaviorClassifier** (токсичность, уход от ответа и т.д.) и решаем, не пора ли завершить звонок досрочно.
  4. Вызываем **тот же LLM-движок виртуального клиента**, что и в боте: на вход — история диалога (в т.ч. только что полученная реплика), на выход — **одна текстовая реплика «клиента»**.
  5. Сохраняем реплику клиента в состоянии сессии (для оценки потом).

Никакой своей ASR на этом шаге не делаем: **мы работаем только с текстом**, который прислал сценарий после ASR. Логика «что ответить» — та же, что в боте (LLM обрабатывает текст и решает, что сказать дальше).

### Шаг 3: Ответ «клиента» в трубку — TTS: у нас или в Voximplant

После шага 2 у нас есть **текст** ответа клиента. Его нужно озвучить и проиграть в звонок. Два варианта.

**Вариант A: TTS в Voximplant (рекомендуется)**

- Бэкенд в ответ на webhook отдаёт только **текст** реплики клиента, например:  
  `{ "reply_text": "Здравствуйте, я интересуюсь автомобилем...", "end_session": false }`
- Сценарий в Voximplant получает этот ответ и вызывает **встроенный TTS** (например `call.say(reply_text, { voice: VoiceList.TBank.ru_RU_Anna })`). Озвучка и воспроизведение идут в облаке Voximplant, без пересылки аудио через наш сервер.
- **Плюсы:** минимальная задержка, один запрос от сценария к нам и один ответ с текстом; не нужна генерация и отдача аудио у нас.
- **Минусы:** голос и язык задаются в сценарии (выбор голосов ограничен провайдерами Voximplant).

**Вариант B: TTS у нас (OpenAI / другой движок)**

- Бэкенд по тексту реплики клиента генерирует аудио (например через OpenAI TTS), сохраняет во временный файл или отдаёт в память, и возвращает сценарию **URL на аудио** (или поток). Сценарий проигрывает этот URL в звонке (например через `call.playback()` по URL).
- **Плюсы:** полный контроль над голосом и качеством; можно менять голос под бренд.
- **Минусы:** лишний шаг (генерация аудио) и отдача файла/потока; задержка выше; нужен публичный URL или поток, доступный Voximplant.

**Рекомендация:** на первом этапе делать **TTS на стороне Voximplant**: бэкенд отдаёт только **текст**, сценарий сам вызывает TTS по этому тексту. Так быстрее и проще. При необходимости позже можно добавить опцию «TTS у нас» и отдавать URL аудио.

### Шаг 4: Цикл и завершение

- После того как сценарий проиграл ответ клиента (TTS), он снова включает приём речи менеджера (ASR) и при появлении следующей реплики снова шлёт текст на наш webhook. Повторяем шаги 1–3, пока не сработает условие завершения (достигнута цель диалога, лимит реплик, ранний выход по BehaviorClassifier и т.д.).
- При завершении бэкенд помечает сессию завершённой, по истории диалога запускает **оценку** (тот же EvaluatorAgent, что в боте), сохраняет результат в БД. Админка и отчёты по сотрудникам/команде используют те же данные.

---

## 4. Сводная таблица: кто что делает

| Этап | Где выполняется | Вход | Выход |
|------|------------------|------|--------|
| ASR | Voximplant (сценарий) | Аудио из звонка (речь менеджера) | Текст реплики → отправляется на наш webhook |
| Обработка текста, состояние, LLM | Наш бэкенд | Текст реплики менеджера, session_id | Текст ответа «клиента» (и при необходимости флаг end_session) |
| TTS (рекомендуемый вариант) | Voximplant (сценарий) | Текст ответа клиента от бэкенда | Озвучка и воспроизведение в звонке |
| TTS (опционально у нас) | Наш бэкенд | Текст ответа клиента | Аудиофайл / URL → сценарий проигрывает по URL |

---

## 5. Краткие ответы на вопросы

- **Что делать с текстом из звонка?**  
  Текст приходит на наш webhook после ASR в Voximplant. Мы добавляем его в историю диалога, при необходимости проверяем через BehaviorClassifier, передаём в **наш LLM** (виртуальный клиент). LLM возвращает текст ответа клиента.

- **Обрабатывает ли наш LLM этот текст?**  
  Да. Тот же движок, что в боте: на вход — история (в т.ч. только что распознанная реплика менеджера), на выход — одна текстовая реплика «клиента».

- **TTS генерировать у нас или в Voximplant?**  
  Эффективнее и быстрее — **в Voximplant**: бэкенд отдаёт только текст, сценарий вызывает встроенный TTS по этому тексту. Генерация TTS на нашей стороне — опция на будущее, если понадобится свой голос или свой движок.

Итого: **самый эффективный по задержке вариант** — ASR и TTS в Voximplant, наш бэкенд только принимает текст, ведёт диалог (состояние + LLM) и отдаёт текст следующей реплики клиента.

---

## 6. Реализация: сценарий voice_dialog и переменные окружения

### 6.1. Переменные окружения

| Переменная | Где используется | Описание |
|------------|-------------------|----------|
| `VOICE_DIALOG_BASE_URL` | vox-smoke-test-server (при `dialog: true`) | Базовый URL **основного приложения** (порт 3000 или туннель), где доступен `POST /voice/dialog`. Пример: `https://your-app.trycloudflare.com`. Без завершающего слеша. |
| `VOX_DIALOG_SCENARIO_NAME` | vox-smoke-test-server | Имя сценария в Voximplant для голосового диалога. По умолчанию: `voice_dialog`. |
| `PUBLIC_BASE_URL` | vox-smoke-test-server | URL сервера звонков (порт 3001), куда Voximplant шлёт события (webhooks). Это **не** то же самое, что `VOICE_DIALOG_BASE_URL`: первый — наш call-test сервер, второй — основное приложение с нейроном. |

При запуске звонка с `dialog: true` сервер передаёт в сценарий `dialog_url = VOICE_DIALOG_BASE_URL + '/voice/dialog'`. Сценарий делает туда POST с `call_id` и текстом от ASR и получает `reply_text` и `end_session`.

### 6.2. Сценарий voice_dialog в Voximplant

Файл **`voximplant/scenario_voice_dialog.js`** реализует полный цикл:

1. **Старт звонка** — из customData читаются `call_id`, `event_url`, `dialog_url`, `to`, `caller_id`.
2. **После ответа (Connected):**  
   `POST dialog_url` с телом `{ call_id }` (без текста) → получение **первой** реплики виртуального клиента → TTS этой реплики.
3. **ASR** — создаётся ASR (профиль T-Bank ru_RU), аудио звонка передаётся в ASR (`call.sendMediaTo(asr)`).
4. **На каждую распознанную фразу (ASREvents.Result):**  
   `POST dialog_url` с телом `{ call_id, text, is_final: true }` → в ответе `reply_text`, `end_session` → TTS реплики; при `end_session === true` — отбой.
5. **События звонка** (progress, connected, disconnected и т.д.) по-прежнему отправляются на `event_url` (vox-smoke-test-server).

Сценарий нужно вставить в Voximplant как отдельный сценарий с именем, совпадающим с `VOX_DIALOG_SCENARIO_NAME` (например, `voice_dialog`), и настроить правило маршрутизации на него (аналогично `smoke_test`).

### 6.3. Как запустить звонок с диалогом

- **Один звонок с диалогом:**  
  `POST /call` с телом `{ "dialog": true }` или `{ "to": "+79...", "dialog": true }`.  
  Должны быть заданы `VOICE_DIALOG_BASE_URL` и (при необходимости) `VOX_DIALOG_SCENARIO_NAME`. Основное приложение (порт 3000) должно быть доступно по этому URL (туннель или прод).
- **Обычный тестовый звонок (одна фраза TTS):**  
  `POST /call` без `dialog` или с `"dialog": false` — используется сценарий `smoke_test`, без вызова нейрона.

---

## 7. Снижение задержек и продвинутые варианты (документация Voximplant)

### 7.1. Что уже сделано

- **Короткие ответы нейрона для голоса:** в `POST /voice/dialog` используется `maxResponseTokens: 220` — модель быстрее завершает ответ.
- **Меньшая пауза после TTS:** в сценарии задержка перед повторным включением ASR снижена (минимум 1.5 с, ~50 мс/символ, макс. 10 с).

### 7.2. Realtime TTS (стриминг текста → озвучка)

В [Realtime speech synthesis](https://voximplant.com/docs/guides/speech/realtime-tts) Voximplant описывает **потоковый TTS**: текст подаётся чанками, озвучка начинается до того, как весь ответ готов. Это особенно полезно при работе с LLM, которые отдают текст по частям.

**Идея:** вместо одного запроса «получить весь `reply_text` → один раз сказать» можно:
- на бэкенде **стримить** ответ LLM (OpenAI `stream: true`);
- сценарий получает чанки текста (например, по **WebSocket**) и передаёт их в **RealtimeTTSPlayer** (ElevenLabs, Cartesia или Inworld);
- воспроизведение начинается с первых фраз, пауза «до первого звука» сокращается.

Провайдеры в сценарии: [ElevenLabs Realtime TTS](https://voximplant.com/docs/guides/speech/realtime-tts#elevenlabs), [Cartesia](https://voximplant.com/docs/guides/speech/realtime-tts#cartesia), [Inworld](https://voximplant.com/docs/guides/speech/realtime-tts#inworld). Для этого варианта нужны: стриминг LLM на бэкенде, WebSocket между бэкендом и сценарием и замена `call.say()` на RealtimeTTSPlayer в сценарии.

### 7.3. WebSocket и передача аудио

В [Media streams → Sending media over WebSockets](https://voximplant.com/docs/guides/media-streams/websocket) описан обмен медиа по WebSocket: можно передавать аудио в звонок и из звонка. Вариант для минимальной задержки: бэкенд генерирует аудио (например, OpenAI TTS) и стримит его в сценарий по WebSocket; сценарий передаёт поток в звонок. Это даёт полный контроль над голосом, но сложнее в реализации и поддержке.

### 7.4. Voice AI (готовые интеграции)

В разделе [Voice AI](https://voximplant.com/docs/voice-ai) описаны интеграции с OpenAI, Google, ElevenLabs и др. Например, [OpenAI Realtime client](https://voximplant.com/docs/voice-ai/openai/realtime-client) — это готовый сценарий «разговор с AI». Если нужна **наша** логика (виртуальный клиент, фазы, темы, поведение), текущая схема «ASR в Vox → наш бэкенд → TTS в Vox» остаётся основной; Realtime TTS и WebSocket — способы ускорить её, не меняя бизнес-логику.
